<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="./Homepage_files/sty/jemdoc.css" type="text/css">
<style type="text/css">
</style>
<title>Weize QUAN - Homepage</title>
<link rel="shortcut icon" href="./Homepage_files/fig/me.jpg" >
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table>
<tbody>
  <tr>
    <td width="19%" valign="top" height="173">
      <img height="225" id="photo" style="padding: 0pt 30pt 0pt 20pt; float: left; display: inline;" src="./Homepage_files/fig/me.jpg">
    </td>
    
    <td width="80%" valign="top" height="173">
      <b><font face="Times New Roman" size="6">Weize QUAN</font><font size="6" face="楷体_GB2312"> （全卫泽）</font><font face="Times New Roman" size="6"></font></b>
      <br><br>      
      <p>
          <br>
          <a href="https://mais.ia.ac.cn/" target="_blank">State Key Laboratory of Multimodal Artificial Intelligence Systems</a>
          <br>
          <a href="http://english.ia.cas.cn/" target="_blank">Institute of Automation Chinese Academy of Sciences</a>
          <br>
          <br>
          Email: qweizework AT gmail.com
      </p>
    </td>
  </tr>
</tbody>
</table>

<h2>Biography</h2>
<p style="text-align:justify;">
  I am currently an Associate Professor at <a href="https://mais.ia.ac.cn/" target="_blank">State Key Laboratory of Multimodal Artificial Intelligence Systems</a>, <a href="http://english.ia.cas.cn/" target="_blank">Institute of Automation Chinese Academy of Sciences</a>. I earned my PhD in 2020 from NLPR, CASIA, advised by <a href="http://people.ucas.ac.cn/~0005319?language=en" target="_blank">Prof. Xiaopeng Zhang</a> and  <a href="https://sites.google.com/site/yandongming/" target="_blank">Prof. Dong-Ming Yan</a>; and from <a href="http://www.gipsa-lab.fr/" target="_blank">GIPSA-Lab</a>, UGA, France, advised by <a href="http://www.gipsa-lab.grenoble-inp.fr/page_pro?vid=97" target="_blank"> Prof. Denis Pellerin</a> and <a href="http://www.gipsa-lab.grenoble-inp.fr/~kai.wang/encadrement_en.html" target="_blank">Dr. Kai Wang</a>. Before that, I received my Bachelor's degree from <a href="http://english.whut.edu.cn/" target="_blank">Wuhan University of Technology</a> in 2014.
</p>
<p> 
  My research interest includes computer graphics, multimodal content understanding and generation, and image forensics.
</p>
      <style>
        .red-text {
            color: DeepPink; /* 设置为红色 */
        }
    </style>
<p>
 <span class="red-text"> I am constantly looking for self-motivated PhD, MSc, and research interns. Welcome, send me your CV via email. </span>
</p>
<h2>Publications</h2>
  
  <p>(<sup>#</sup>Joint first authors, <sup>*</sup>Corresponding author)</p>
  
  <table border="0" width="100%">
  <tbody> 
      
    <!-- GoHD: Gaze-oriented and Highly Disentangled Portrait Animation with Rhythmic Poses and Realistic Expressions -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./2025/GoHD/teaser.png" alt="">
        </div>
      </td>
      <td>
        <a href="./2025/GoHD/GoHD.pdf" target="_blank">GoHD: Gaze-oriented and Highly Disentangled Portrait Animation with Rhythmic Poses and Realistic Expressions</a>        
        <br> 
        Ziqi Zhou,
        <strong>Weize Quan</strong><sup>*</sup>,
        Hailin Shi,
        Wei Li,
        Lili Wang,
        Dong-Ming Yan
        <br> 
        <i>AAAI, 2025</i>
        <br>
        [<a href="./2025/GoHD/GoHD.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/Jia1018/GoHD" target="_blank"> Code</a>]
      </td>
    </tr>
    </p>  
    
    <!-- PointCFormer: a Relation-based Progressive Feature Extraction Network for Point Cloud Completion -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./2025/PointCFormer/teaser.png" alt="">
        </div>
      </td>
      <td>
        <a href="./2025/PointCFormer/PointCFormer.pdf" target="_blank">PointCFormer: a Relation-based Progressive Feature Extraction Network for Point Cloud Completion</a>        
        <br> 
        Yi Zhong,
        <strong>Weize Quan</strong>,
        Dong-Ming Yan,
        Jie Jiang,
        Yingmei Wei
        <br> 
        <i>AAAI, 2025</i>
        <br>
        [<a href="./2025/PointCFormer/PointCFormer.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/Zyyyyy0926/PointCFormer_Plus_Pytorch" target="_blank">Code</a>]
      </td>
    </tr>
    </p>
    
    <!-- M2HF: Multi-branch Multi-modal Hybrid Fusion for Text-Video Retrieval -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./2025/M2HF/teaser.png" alt="">
        </div>
      </td>
      <td>
        <a href="./2025/M2HF/M2HF.pdf" target="_blank">M2HF: Multi-branch Multi-modal Hybrid Fusion for Text-Video Retrieval</a>        
        <br> 
        Shuo Liu,
        <strong>Weize Quan</strong>,
        Ming Zhou,
        Sihong Chen,
        Jian Kang,
        Zhe Zhao,
        Kimmo Yan,
        Chen Chen,
        Dong-Ming Yan
        <br> 
        <i>CVM, 2025</i>
        <br>
        [<a href="./2025/M2HF/M2HF.pdf" target="_blank">PDF</a>]
      </td>
    </tr>
    </p>

        <table id="portfolio-projects">
    <tbody>
      <br><b><h3>2024</h3></b>
    <!-- VQ-CAD: Computer-Aided Design Model Generation with Vector Quantized Diffusion -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./2024/CAGD/teaser.jpg" alt="">
        </div>
      </td>
      <td>
        <a href="./2024/CAGD/VQ-CAD.pdf" target="_blank">VQ-CAD: Computer-Aided Design Model Generation with Vector Quantized Diffusion</a>        
        <br> 
        Hanxiao Wang,
        Mingyang Zhao<sup>*</sup>,
        Yiqun Wang,
        <strong>Weize Quan</strong><sup>*</sup>,
        Dong-Ming Yan
        <br> 
        <i>Computer Aided Geometric Design, vol. 111, pp. 102327, 2024</i>
        <br>
        [<a href="./2024/CAGD/VQ-CAD.pdf" target="_blank">PDF</a>]
      </td>
    </tr>
    </p>
    
    <!-- Neural Parametric Human Hand Modeling with Point Cloud Representation -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./2024/ICMR/teaser.jpg" alt="">
        </div>
      </td>
      <td>
        <a href="./2024/ICMR/ICMR_2024.pdf" target="_blank">Neural Parametric Human Hand Modeling with Point Cloud Representation</a>        
        <br> 
        Jian Yang,
        <strong>Weize Quan</strong>,
        Zhen Shen,
        Dong-Ming Yan,
        Huai-Yu Wu
        <br> 
        <i>International Conference on Multimedia Retrieval, pp. 804-813, 2024</i>
        <br>
        [<a href="./2024/ICMR/ICMR_2024.pdf" target="_blank">PDF</a>]
      </td>
    </tr>
    </p>
    
    <!-- Deep Learning-based Image and Video Inpainting: A Survey -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./2024/IJCV-Survey/inpainting_survey.png" alt="">
        </div>
      </td>
      <td>
        <a href="./2024/IJCV-Survey/Inpainting_survey1.pdf" target="_blank">Deep Learning-based Image and Video Inpainting: A Survey</a>        
        <br> 
        <strong>Weize Quan</strong>,
        Jiaxi Chen,
        Yanli Liu,
        Dong-Ming Yan,
        Peter Wonka
        <br> 
        <i>International Journal of Computer Vision, vol. 132, pp. 2367–2400, 2024</i>
        <br>
        [<a href="./2024/IJCV-Survey/Inpainting_survey1.pdf" target="_blank">PDF</a>]
      </td>
    </tr>
    </p>
    
    <!-- CMG-Net: Robust Normal Estimation for Point Clouds via Chamfer Normal Distance and Multi-scale Geometry -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./2024/AAAI/point.png" alt="">
        </div>
      </td>
      <td>
        <a href="./2024/AAAI/point.pdf" target="_blank">CMG-Net: Robust Normal Estimation for Point Clouds via Chamfer Normal Distance and Multi-scale Geometry</a>        
        <br> 
        Yingrui Wu,
        Mingyang Zhao,
        Keqiang Li,
        <strong>Weize Quan</strong>,
        Tianqi Yu,
        Jianfeng Yang,
        Xiaohong Jia,
        Dong-Ming Yan
        <br> 
        <i>The Annual AAAI Conference on Artificial Intelligence, 2024</i>
        <br>
        [<a href="./2024/AAAI/point.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/YingruiWoo/CMG-Net_Pytorch" target="_blank">Code</a>]
      </td>
    </tr>
    </p>
    
    <!-- CGFormer: ViT-Based Network for Identifying Computer-Generated Images with Token Labeling -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./2023/CGFormer/CGFormer.png" alt="">
        </div>
      </td>
      <td>
        <a href="./2023/CGFormer/CGFormer_ViT.pdf" target="_blank">CGFormer: ViT-Based Network for Identifying Computer-Generated Images with Token Labeling</a>        
        <br> 
        <strong>Weize Quan</strong>,
        Pengfei Deng,
        Kai Wang,
        Dong-Ming Yan
        <br> 
        <i>IEEE Transactions on Information Forensics & Security, vol. 19, pp. 235-250, 2024</i>
        <br>
        [<a href="./2023/CGFormer/CGFormer_ViT.pdf" target="_blank">PDF</a>]
        [<a href=" https://github.com/feipiefei/CGFormer" target="_blank">Code</a>]
      </td>
    </tr>
    </p>
      </tbody>
</table>  
  
    <br><b><h3>2023</h3></b>
    <table id="portfolio-projects">
    <tbody>
    <!-- Layout-Aware Single-Image Document Flattening -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./2023/TOG/2023-TOG-DocFlattening.png" alt="">
        </div>
      </td>
      <td>
        <a>Layout-Aware Single-Image Document Flattening</a>        
        <br> 
        Pu Li,
        <strong>Weize Quan</strong>,
        Jianwei Guo,
        Dong-Ming Yan
        <br> 
        <i>ACM Transactions on Graphics, 43(1), No.9:1-17, 2023</i>
        <br>
        [<a>PDF</a>]
        [<a>Suppl</a>]
        [<a href="https://github.com/BunnySoCrazy/LA-DocFlatten" target="_blank"> Code & Dataset</a>]
      </td>
    </tr>
    </p>  
    
    <!-- DPE: Disentanglement of Pose and Expression for General Video Portrait Editing -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./2023/DPE/dpe.png" alt="">
        </div>
      </td>
      <td>
        <a href="./2023/DPE/dpe_PDF.pdf" target="_blank">DPE: Disentanglement of Pose and Expression for General Video Portrait Editing</a>        
        <br> 
        Youxin Pang,
        Yong Zhang,
        <strong>Weize Quan</strong>,
        Yanbo Fan,
        Xiaodong Cun,
        Ying Shan,
        Dong-Ming Yan
        <br> 
        <i>Computer Vision and Pattern Recognition, pp. 427-436, 2023</i>
        <br>
        [<a href="./2023/DPE/dpe_PDF.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/Carlyx/DPE" target="_blank">Code</a>]
      </td>
    </tr>
    </p>
    
    <!-- W-Net: Structure and Texture Interaction for Image Inpainting -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./wnet2022/wnet.png" alt="">
        </div>
      </td>
      <td>
        <a href="./wnet2022/W-Net.pdf" target="_blank">W-Net: Structure and Texture Interaction for Image Inpainting</a>        
        <br> 
        Ruisong Zhang<sup>#</sup>,
        <strong>Weize Quan</strong><sup>#</sup>,
        Yong Zhang,
        Jue Wang,
        Dong-Ming Yan
        <br> 
        <i>IEEE Transactions on Multimedia, vol. 25, pp. 7299-7310, 2023</i>
        <br>
        [<a href="./wnet2022/W-Net.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/Evergrow/W-Net" target="_blank">Code</a>]
      </td>
    </tr>
    </p>

    <!-- Dense Modality Interaction Network for Audio-Visual Event Localization -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./AVED_TMM2022/highlight.png" alt="">
        </div>
      </td>
      <td>
        <a href="./AVED_TMM2022/paper_compressed.pdf" target="_blank">Dense Modality Interaction Network for Audio-Visual Event Localization</a>        
        <br> 
        Shuo Liu<sup>#</sup>, 
        <strong>Weize Quan</strong><sup>#</sup>,
        Chaoqun Wang,
        Yuan Liu,
        Bin Liu,
        Dong-Ming Yan
        <br> 
        <i>IEEE Transactions on Multimedia, vol. 25, pp. 2734-2748, 2023</i>
        <br>
        [<a href="./AVED_TMM2022/paper_compressed.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/weizequan/DMIN.git" target="_blank">Code</a>]
      </td>
    </tr>
  </p>
  </tbody>
</table>  
    
    <br><b><h3>2022</h3></b>
    <table id="portfolio-projects">
    <tbody>
    <!-- Neural Texture Transfer Assisted Video Coding with Adaptive Up-sampling -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./SPIC2022/overview.png" alt="">
        </div>
      </td>
      <td>
        <a href="./SPIC2022/paper.pdf" target="_blank">Neural Texture Transfer Assisted Video Coding with Adaptive Up-sampling</a>        
        <br> 
        Li Yu, 
        Wenshuai Chang, 
        <strong>Weize Quan</strong>,
        Jimin Xiao, 
        Dong-Ming Yan, 
        Moncef Gabbouj
        <br> 
        <i>Signal Processing: Image Communication, 2022</i>
        <br>
        [<a href="./SPIC2022/paper.pdf" target="_blank">PDF</a>]
      </td>
    </tr>
    </p>
    
    <!-- Image Inpainting with Local and Global Refinement -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./TIP2022/teaser2.png" alt="">
        </div>
      </td>
      <td>
        <a href="./TIP2022/Image_Inpainting_with_Local_and_Global_Refinement-compressed.pdf" target="_blank">Image Inpainting with Local and Global Refinement</a>        
        <br> 
        <strong>Weize Quan</strong>,
        Ruisong Zhang,
        Yong Zhang,
        Zhifeng Li,
        Jue Wang,
        Dong-Ming Yan
        <br> 
        <i>IEEE Transactions on Image Processing, vol. 31, pp. 2405 - 2420, 2022.</i>
        <br>
        [<a href="./TIP2022/Image_Inpainting_with_Local_and_Global_Refinement-compressed.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/weizequan/LGNet" target="_blank">Code</a>]
      </td>
    </tr>
    </p>
    
    <!-- Bi-directional Modality Fusion Network for Audio-Visual Event Localization -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./AVED_ICASSP2022/highlight.png" alt="">
        </div>
      </td>
      <td>
        <a href="./AVED_ICASSP2022/paper.pdf" target="_blank">Bi-directional Modality Fusion Network for Audio-Visual Event Localization</a>        
        <br> 
        Shuo Liu, 
        <strong>Weize Quan</strong><sup>*</sup>, 
        Yuan Liu,
        Dong-Ming Yan
        <br> 
        <i>ICASSP, 4868-4872, 2022</i>
        <br>
        [<a href="./AVED_ICASSP2022/paper.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/weizequan/BMFN" target="_blank">Code</a>]
      </td>
    </tr>
    </p>
    
    <!-- Scene Text Removal via Cascaded Text Stroke Detection and Erasing -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./Text2020/Text2020.png" alt="">
        </div>
      </td>
      <td>
        <a href="./Text2020/Text2020.pdf" target="_blank">Scene Text Removal via Cascaded Text Stroke Detection and Erasing</a>        
        <br> 
        Xuewei Bian<sup>#</sup>, 
        Chaoqun Wang<sup>#</sup>,
        <strong>Weize Quan</strong><sup>*</sup>, 
        Juntao Ye, 
        Xiaopeng Zhang, 
        Dong-Ming Yan
        <br> 
        <i>Computational Visual Media, vol. 8, pp. 273–287, 2022</i>
        <br>
        [<a href="./Text2020/2022_Article_.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/wcq19941215/SceneTextRemoval" target="_blank">Code</a>]
      </td>
    </tr>
    </p>
      </tbody>
</table>  
      
    <br><b><h3>2021</h3></b>
    <table id="portfolio-projects">
    <tbody>
    <!-- Deep Video Decaptioning -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./BMVC2021/fig1.png" alt="">
        </div>
      </td>
      <td>
        <a href="./BMVC2021/0651.pdf" target="_blank">Deep Video Decaptioning</a>        
        <br> 
        Pengpeng Chu<sup>#</sup>, 
        <strong>Weize Quan</strong><sup>#</sup>, 
        Tong Wang,
        Pan Wang,
        Peiran Ren, 
        Dong-Ming Yan
        <br> 
        <i>British Machine Vision Conference, 2021</i>
        <br>
        [<a href="./BMVC2021/0651.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/Linya-lab/Video_Decaptioning" target="_blank">Code</a>]
      </td>
    </tr>
    </p>
    
    <!-- Text-Aware Single Image Specular Highlight Removal -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./PRCV2021/highlight.png" alt="">
        </div>
      </td>
      <td>
        <a href="./PRCV2021/paper.pdf" target="_blank">Text-Aware Single Image Specular Highlight Removal</a>        
        <br> 
        Shiyu Hou, 
        Chaoqun Wang,
        <strong>Weize Quan</strong>, 
        Jingen Jiang, 
        Dong-Ming Yan
        <br> 
        <i>PRCV, 2021</i>
        <br>
        [<a href="./PRCV2021/paper.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/weizequan/TASHR" target="_blank">Code</a>]
      </td>
    </tr>
    </p>
    
    <!-- Efficient Center Voting for Object Detection and 6D Pose Estimation in 3D Point Cloud -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./TIP2021/2021_TIP_6DPose.png" alt="">
        </div>
      </td>
      <td>
        <a href="./TIP2021/2021_TIP_6DPose.pdf" target="_blank">Efficient Center Voting for Object Detection and 6D Pose Estimation in 3D Point Cloud</a>        
        <br> 
        Jianwei Guo,
        Xuejun Xing,
        <strong>Weize Quan</strong>, 
        Dong-Ming Yan, 
        Qingyi Gu, 
        Yang Liu, 
        Xiaopeng Zhang
        <br> 
        <i>IEEE Transactions on Image Processing, vol. 30, pp. 5072-5084, 2021.</i>
        <br>
        [<a href="./TIP2021/2021_TIP_6DPose.pdf" target="_blank">PDF</a>]
      </td>
    </tr>
    </p>
  </tbody>
</table>  
      
    <br><b><h3>2020</h3></b>
    <table id="portfolio-projects">
    <tbody>
    <!-- Pixel-wise Dense Detector for Image Inpainting -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./GDN_Inpainting_files/Cover.png" alt="">
        </div>
      </td>
      <td>
        <a href="http://evergrow.github.io/" target="_blank">Pixel-wise Dense Detector for Image Inpainting</a>        
        <br> 
        Ruisong Zhang, 
        <strong>Weize Quan</strong>, 
        Baoyuan Wu, 
        Zhifeng Li,
        Dong-Ming Yan
        <br> 
        <i>Computer Graphic Forum, (Proc. of Pacific Graphics), 2020</i>
        <br>
        [<a href="GDN_Inpainting.html" target="_blank">Project Page</a>]
        [<a href="./GDN_Inpainting_files/GDN_Inpainting.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/Evergrow/GDN_Inpainting" target="_blank">Code</a>]
        <!-- [<a href="GDN_Inpainting_files/GDN_Inpainting_Supplement.pdf" target="_blank">Supplement</a>] -->
        <!-- [<a href="./NIvsCG_files/NIvsCG_Slides.pdf" target="_blank">Slides</a>] -->
      </td>
    </tr>
    </p>
    
    <!-- Learn with Diversity and from Harder Samples: Improving the Generalization of CNN-Based Detection of Computer-Generated Images -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./DI2020/dataset.jpg" alt="">
        </div>
      </td>
      <td>
        <a href="./DI2020/paper.pdf" target="_blank">Learn with Diversity and from Harder Samples: Improving the Generalization of CNN-Based Detection of Computer-Generated Images</a>        

        
        <br> 
        <strong>Weize Quan</strong>,       
        Kai Wang, 
        Dong-Ming Yan,
        Xiaopeng Zhang, 
        Denis Pellerin

        <br> 
        <i>Forensic Science International: Digital Investigation, 35:301023, 2020</i>
        
        <br>
  [<a href="./DI2020/paper.pdf" target="_blank">PDF</a>]
  [<a href="https://github.com/weizequan/CGDetection" target="_blank">Code&Dataset</a>]
        

      </td>
    </tr>
    </p>
    
      <p>
      <tr>
      <td>
        <div align="center">
          <img width="180" src="./NIvsCG_files_JCST/comp.png" alt="">
        </div>
      </td>
      <td>
        <a href="http://jcst.ict.ac.cn/EN/10.1007/s11390-020-0216-9" target="_blank">Distinguishing Computer-Generated Images from Natural Images Using Channel and Pixel Correlation</a>        
        <br> 
        Ruisong Zhang, 
        <strong>Weize Quan</strong>, 
        Lubin Fan, 
        Liming Hu,
        Dong-Ming Yan
        <br> 
        <i>Journal of Computer Science and Technology, 2020</i>
        <br>
        [<a href="./NIvsCG_files_JCST/NIvsCG.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/Evergrow/JCST_NIvsCG" target="_blank">Code</a>] 
  [<a href="./NIvsCG_files_JCST/NIvsCG_Slides.pdf" target="_blank">Slides</a>]
      </td>
    </tr>
    </p>
  </tbody>
</table>  
      
    <br><b><h3>2019</h3></b>
    <table id="portfolio-projects">
    <tbody>
    <!-- Improving the Generalization of Colorized Image Detection with Enhanced Training of CNN -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./ISPA2019/colorization.jpg" alt="">
        </div>
      </td>
      <td>
        <a href="./ISPA2019/paper.pdf" target="_blank">Improving the Generalization of Colorized Image Detection with Enhanced Training of CNN</a>        

        
        <br> 
        <strong>Weize Quan</strong>,       
        Kai Wang, 
        Dong-Ming Yan,
        Denis Pellerin,
        Xiaopeng Zhang     
        
        <br> 
        <i>International Symposium on Image and Signal Processing and Analysis, 246-252, 2019</i>
        
        <br>
  [<a href="./ISPA2019/paper.pdf" target="_blank">PDF</a>]
  [<a href="https://github.com/weizequan/NIvsCI" target="_blank">Code</a>] 
        

      </td>
    </tr>
    </p>


    <!-- Impact of Data Preparation and CNN’s First Layer on Performance of Image Forensics: A Case Study of Detecting Colorized Images -->
   <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./WI2019/filter_FFT.jpg" alt="">
        </div>
      </td>
      <td>
        <a href="./WI2019/paper.pdf" target="_blank">Impact of Data Preparation and CNN’s First Layer on Performance of Image Forensics: A Case Study of Detecting Colorized Images</a>        

        
        <br> 
        <strong>Weize Quan</strong>,       
        Kai Wang, 
        Dong-Ming Yan,
        Denis Pellerin,
        Xiaopeng Zhang     
        
        <br> 
        <i>International Workshop on Machine Learning Algorithms for Cybersecurity, 127–131, 2019</i>
        
        <br>
        [<a href="./WI2019/paper.pdf" target="_blank">PDF</a>]

      </td>
    </tr>
    </p>
  </tbody>
</table>  
      
   <br><b><h3>2018</h3></b>
    <table id="portfolio-projects">
    <tbody>
    <!-- Distinguishing between Natural and Computer-Generated Images Using Convolutional Neural Networks -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./NIvsCG_files/comp.png" alt="">
        </div>
      </td>
      <td>
        <a href="./NIvsCG_files/NIvsCG.pdf" target="_blank">Distinguishing between Natural and Computer-Generated Images Using Convolutional Neural Networks</a>        
        <br> 
  <strong>Weize Quan</strong>, 
        Kai Wang, 
        Dong-Ming Yan, 
        Xiaopeng Zhang
        <br> 
        <i>IEEE Transactions on Information Forensics & Security, vol. 13, no. 11, pp. 2772-2787, 2018</i>
        <br>
        [<a href="NIvsCG.html" target="_blank">Project page</a>]
  [<a href="./NIvsCG_files/NIvsCG.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/weizequan/NIvsCG" target="_blank">Code</a>] 
      
      </td>
    </tr>
    </p>

    <!-- Learning 3D Keypoint Descriptors for Non-Rigid Shape Matching -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./ECCV2018/2018_ECCV_descriptor.png" alt="">
        </div>
      </td>
      <td>
        <a href="./ECCV2018/2018_ECCV_localDescriptors.pdf" target="_blank">Learning 3D Keypoint Descriptors for Non-Rigid Shape Matching</a>        
        <br> 
        Hanyu Wang, 
        Jianwei Guo, 
        Dong-Ming Yan,
        <strong>Weize Quan</strong>, 
        Xiaopeng Zhang
        <br> 
        <i>European Conference on Computer Vision, pp. 3-19, 2018.</i>
        <br>
        [<a href="./ECCV2018/2018_ECCV_localDescriptors.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/jianweiguo/local3Ddescriptorlearning" target="_blank">Code</a>] 
      </td>
    </tr> 
    </p>
  </tbody>
</table>  
      
    <br><b><h3>Before 2018</h3></b>
    <table id="portfolio-projects">
    <tbody>
    <!-- Maximal Poisson-disk Sampling via Sampling Radius Optimization -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./mps2016/uniform_2d.jpg" alt="">
        </div>
      </td>
      <td>
        <a href="./mps2016/MPS.pdf" target="_blank">Maximal Poisson-disk Sampling via Sampling Radius Optimization</a>        

        
        <br> 
        <strong>Weize Quan</strong>, 
        Dong-Ming Yan, 
        Jianwei Guo, 
        Weiliang Meng, 
        Xiaopeng Zhang       
        
        <br> 
        <i>SIGGRAPH ASIA 2016 Posters</i>
        
        <br> 
  [<a href="./mps2016/MPS.pdf" target="_blank">PDF</a>]
        [<a href="https://github.com/weizequan/MPS" target="_blank">Code</a>] 

      </td>
    </tr>
    </p>

    <!-- Improved Quadric Surfaces Recognition from Scanned Mechanical Models -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./CADDM2016/CADDM2016.png" alt="">
        </div>
      </td>
      <td>
        <a href="./CADDM2016/CADDM2016.pdf" target="_blank">Improved Quadric Surfaces Recognition from Scanned Mechanical Models</a>        
        
        <br> 
        <strong>Weize Quan</strong>, 
        Jianwei Guo, 
        Xiaopeng Zhang,
        Dong-Ming Yan  
        
        <br> 
        <i>Computer Aided Drafting, Design and Manufacturing, 26(4), 2016</i>
        
        <br> 
       [<a href="./CADDM2016/CADDM2016.pdf" target="_blank">PDF</a>]
      </td>
    </tr>
    </p>

    <!-- Analyzing Surface Sampling Patterns Using the Localized Pair Correlation Function -->
    <p>
    <tr>
      <td>
        <div align="center">
          <img width="180" src="./LPCF2016/3d_adaptive.jpg" alt="">
        </div>
      </td>
      <td>
        <a href="./LPCF2016/LPCF.pdf" target="_blank">Analyzing Surface Sampling Patterns Using the Localized Pair Correlation Function</a>        

        
        <br> 
        <strong>Weize Quan</strong>,       
        Jianwei Guo,
        Dong-Ming Yan,
        Weiliang Meng, 
        Xiaopeng Zhang       
        
        <br> 
        <i>Computational Visual Media, 2(3): 219-230, 2016</i>
        
        <br>
        [<a href="./LPCF2016/LPCF.pdf" target="_blank">PDF</a>]

      </td>
    </tr>
    </p>

  </tbody>
</table>  

<h2>Professional Services</h2>
  
<h3>Editorial Board<br></h3>
    <p>
    The Visual Computer (TVCJ), Associate Editor (2024 - )
    </p>

<h3>Program Committee<br></h3>
    <ul>
    <li> CVM 2024 </li> 
    <li> GDC 2022 - 2023 </li>
    </ul>

<h3>Paper Reviewer<br></h3>
    <ul>
    <li>TIP, TIFS, TMM, TCSVT, CVMJ, PR, TVCJ, SPIC, CVIU</li> 
    <li>CVPR, CVM, GMP</li>
    </ul>
  
<h2>Research Experiences</h2>
<table id="tbExperiences" border="0" width="100%">
  <tbody>
    <tr>
      <td> Apr. 2018 - Jun. 2019 &nbsp; UCAS Joint Ph.D. Training Program, Université Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, Directed by <a href="http://www.gipsa-lab.grenoble-inp.fr/page_pro?vid=97" target="_blank"> Prof. Denis Pellerin</a> and <a href="http://www.gipsa-lab.grenoble-inp.fr/~kai.wang/encadrement_en.html" target="_blank">Dr. Kai Wang</a>
    </tr>
    <tr>
      <td> Mar. 2017 - Sep. 2017 &nbsp; Visiting Ph.D. student, Université Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, Directed by <a href="http://www.gipsa-lab.grenoble-inp.fr/~kai.wang/encadrement_en.html" target="_blank">Dr. Kai Wang</td>
    </tr>
  <tr>
      <td> Sep. 2016 - Jan. 2017 &nbsp; Intern student, Huawei Technologies Co., Ltd. Shenzhen</td>
    </tr>
  </tbody>
</table>

</div>
</body>
</html>
